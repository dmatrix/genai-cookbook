{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f470274a-56a3-447e-9bd3-2dbb9c858f55",
   "metadata": {},
   "source": [
    "## Zero-shot prompting\n",
    "\n",
    "Zero-prompt learning is a challenging yet fascinating area where models are trained to perform tasks without explicit learning examples in the input prompt. Here are some notable examples:\n",
    "\n",
    "GPT-3 and Llama Language Model:\n",
    "\n",
    "GPT-3, Llama 2, and Claude are powerful language models. The have demonstrated zero-shot learning. That is, without specific learning prompts or examples, it can generate coherent and contextually relevant responses, showcasing its ability to understand and respond to diverse queries.\n",
    "\n",
    "### Named Entity Recognition (NER):\n",
    "\n",
    "Models trained with zero-prompt learning for NER can identify and categorize named entities in text without being explicitly provided with examples for each specific entity.\n",
    "\n",
    "### Dialogue Generation:\n",
    "\n",
    "Zero-shot dialogue generation models can engage in conversations and respond appropriately to user input without being given explicit dialogues as training examples.\n",
    "\n",
    "In our prompt engineering notebooks, we saw examples of zero-shot prompting: Text generation, summarization, translation, etc. None of the prompts were given any language examples to learn from; they model has prior learned knowledge of the language. \n",
    "\n",
    "Let's demonstrate how you can do NER and Dialogue generation with zero-shot learning.\n",
    "\n",
    "**Note**: \n",
    "To run any of these relevant notebooks you will need an account on Anyscale Endpoints and\n",
    "OpenAI. Use the template enivironment files to create respective `.env` file for either \n",
    "Anyscale Endpoints or OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31635bd-4004-49c5-bab3-7280670e67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25750774-ecc5-45b9-b8d8-840263034029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191aef22-93de-4b61-8841-c67bf8dd2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cdc3909-da39-446a-a453-3592eabb5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c9661d6-0d2a-470d-8ead-946c4f8b1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                    You must complete any incomplete sentence by drawing from your vast\n",
    "                    knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\n",
    "                    You can also identify and categorize named entities.\n",
    "                    You are also an helpful assitant to converse in a dialogue.\n",
    "                  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186876d-310c-4255-8f22-0f30863e8834",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f27d673-7d09-47c5-b0ad-fc9b0c43c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = \"\"\"Tesla, headquartered in Palo Alto, was founded by Elon Musk. \n",
    "The company recently announced a collaboration with NASA to explore sustainable technologies for space travel.\"\"\"\n",
    "\n",
    "zero_learning_prompt = f\"\"\"Analyze the text provided in three ticks and identify the named entities present. \n",
    "Categorize them into types such as persons, organizations, and locations. \n",
    "'''{user_text}'''.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "917cce3b-db4d-40e3-996e-2f6ff556b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:\n",
      "\n",
      "1. Tesla - Organization\n",
      "2. Palo Alto - Location\n",
      "3. Elon Musk - Person\n",
      "4. NASA - Organization\n",
      "\n",
      "These entities are categorized as follows:\n",
      "\n",
      "- Tesla: An electric vehicle and clean energy company.\n",
      "- Palo Alto: A city in California, United States, where Tesla's headquarters were previously located before moving to Austin, Texas.\n",
      "- Elon Musk: An entrepreneur and business magnate known for founding SpaceX and co-founding Tesla, among other ventures.\n",
      "- NASA: The National Aeronautics and Space Administration, a United States government agency responsible for the nation's civilian space program and for aeronautics and aerospace research.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, zero_learning_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a99958-94da-4420-84ad-aca486c6b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = \"\"\" In the year 1969, Neil Armstrong became the first person to walk on the moon during the Apollo 11 mission. \n",
    "NASA, headquartered in Washington D.C., spearheaded this historic achievement. \n",
    "Armstrong's fellow astronaut, Buzz Aldrin, joined him in this extraordinary venture. \n",
    "The event took place on July 20, 1969, forever marking a significant milestone in human history.\"\n",
    "\"\"\"\n",
    "zero_learning_prompt = f\"\"\"Analyze the text provided in three ticks and identify the named entities present. \n",
    "Categorize them into types such as persons, organizations, and locations. \n",
    "'''{user_text}'''.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cad62ffd-65cc-48d5-860a-e26a01e6be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:\n",
      "\n",
      "1. Neil Armstrong - Person\n",
      "2. Apollo 11 - Organization (Space Mission)\n",
      "3. NASA - Organization\n",
      "4. Washington D.C. - Location\n",
      "5. Buzz Aldrin - Person\n",
      "6. July 20, 1969 - Date\n",
      "\n",
      "Categorization:\n",
      "\n",
      "- Persons: Neil Armstrong, Buzz Aldrin\n",
      "- Organizations: NASA, Apollo 11\n",
      "- Locations: Washington D.C.\n",
      "- Date: July 20, 1969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, zero_learning_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be938c-37d3-406b-8c6e-159c8e9e6a93",
   "metadata": {},
   "source": [
    "## Dialogue Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "762eb764-429f-4128-ad6d-b9779e772017",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = \"\"\"Hello, I've been experiencing issues with the software. It keeps crashing whenever I try to open a specific file. \n",
    "Can you help?\n",
    "\"\"\"\n",
    "dialogue_zero_learning_promt = f\"\"\"Generate a conversation between a customer and a support agent discussing a technical issue related to a software product\n",
    "provided in the {user_text}. \n",
    "Note that the model has not been provided with specific examples of this dialogue during training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "818823d5-b0ed-4559-926c-eee27c5423ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Agent: Hello! I'm really sorry to hear that you're having trouble with our software. I'll do my best to assist you. In order to help you more effectively, could you please tell me which software product you are using and the type of file you're trying to open?\n",
      "\n",
      "Customer: Sure, I'm using the latest version of your photo editing software, QuickEdit Pro, and I'm trying to open a .raw file from my new camera.\n",
      "\n",
      "Support Agent: Thank you for that information. It sounds like there might be a compatibility issue with the .raw file from your camera. QuickEdit Pro usually supports .raw files, but it could be that the file is from a camera model that we need to update our software to support. Could you tell me the make and model of your camera?\n",
      "\n",
      "Customer: It's a Nikon Z6 II.\n",
      "\n",
      "Support Agent: Thank you for providing that. Let me quickly check our system for any known issues with that camera model. One moment, please.\n",
      "\n",
      "(After a brief pause)\n",
      "\n",
      "Support Agent: I've checked our database, and it appears that we recently released an update to support .raw files from the Nikon Z6 II. Do you know if your software is up to date with the latest version?\n",
      "\n",
      "Customer: I'm not sure, actually. How do I check for updates?\n",
      "\n",
      "Support Agent: If you open QuickEdit Pro, go to the 'Help' menu and select 'Check for Updates.' If an update is available, it will prompt you to download and install it. Can you try that for me now?\n",
      "\n",
      "Customer: Okay, let me check... Oh, it looks like there is an update available. I didn't realize I was running an older version. I'm downloading the update now.\n",
      "\n",
      "Support Agent: Great! Once the update is installed, try reopening the .raw file and let me know if it opens without crashing.\n",
      "\n",
      "(After a short wait)\n",
      "\n",
      "Customer: The update is installed, and I've just tried the file again. It's working perfectly now! Thanks so much for your help.\n",
      "\n",
      "Support Agent: You're welcome! I'm glad to hear that solved the problem. If you have any more issues or questions, please don't hesitate to reach out. Enjoy using QuickEdit Pro, and have a great day!\n",
      "\n",
      "Customer: Will do, thanks again. Goodbye!\n",
      "\n",
      "Support Agent: Goodbye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, dialogue_zero_learning_promt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b3682-fac7-44e3-8526-5bcb2f421daf",
   "metadata": {},
   "source": [
    "## All this is amazing! üòú Feel the wizardy prompt power üßô‚Äç‚ôÄÔ∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
