{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39330ca8-0778-405c-8d1f-2c31e190ebde",
   "metadata": {},
   "source": [
    "## Natural language processing (NLP) LLM Tasks\n",
    "This notebook goes a bit futher with diverse examples to demonstrate various tasks, emphasizing effective usage of prompt engineering through practical instances and using [CO-STAR prompt framework](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) for \n",
    "eliciting the best response from the LLM\n",
    "\n",
    "The tasks explored in this notebook, using sophiscated prompting techniques, show *how-to* code examples for common natural language understanfing capabilites of a generalized LLM, such as ChatGPT and Llama 2 series:\n",
    "\n",
    " * Text generation or completion\n",
    " * Text summarization\n",
    " * Text extraction\n",
    " * Text classification or sentiment analysis\n",
    " * Text categorization\n",
    " * Text transformation and translation\n",
    " * Simple and complex reasoning\n",
    "\n",
    "<img src=\"./images/llm_prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n",
    "**Note**: \n",
    "To run any of these relevant notebooks you will need an account on Anyscale Endpoints, Anthropic, Gemini, or OpenAI, depending on what model you elect, along with the respective environment file. Use the template environment files to create respective `.env` file for either Anyscale Endpoints, Anthropic, or OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798bde8f-44a7-4e9f-ba30-0ffccd1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d617225a-eb51-4d76-a324-bc1547759d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_BEGIN = \"\\033[1m\"\n",
    "BOLD_END = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249c0446-7d74-402b-b7a5-9ab6f1d59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "api_key = os.getenv(\"GOOLE_API_KEY\")\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(MODEL)\n",
    "print(f\"Using MODEL={MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8654cd8-fa3d-4d94-a7c9-37053a3434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_clnt_factory_api import ClientFactory, get_commpletion\n",
    "\n",
    "client_factory = ClientFactory()\n",
    "client_factory.register_client('google', genai.GenerativeModel)\n",
    "client_type = 'google'\n",
    "client_kwargs = {\"model_name\": \"gemini-1.5-flash\",\n",
    "                     \"generation_config\": {\"temperature\": 0.8,}\n",
    "                }\n",
    "\n",
    "client = client_factory.create_client(client_type, **client_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06061-ea86-4e09-b006-9a0c61f92e33",
   "metadata": {},
   "source": [
    "## Text generation or completion\n",
    "In this simple task, we use an LLM to generate text by finishing an incomplete user content provided in the prompt. For example,\n",
    "by providing an incomplete prompt such as \"On a cold winter night, the stray dog ...\". \n",
    "\n",
    "Let's try a few text generation or completion tasks by providing partial prompts in the user content. You will surprised at its fluency and coherency in the generated text.\n",
    "\n",
    "For prompting, we use the C0-STAR framework.\n",
    "\n",
    "<img src=\"./images/co-star-framework.png\" height=\"35%\" width=\"%65\">\n",
    "\n",
    "\n",
    "**(C): Context: Provide background and information on the task**\n",
    "\n",
    "**(O): Objective: Define the task that you want the LLM to perform**\n",
    "\n",
    "**(S): Style: Specify the writing style you want the LLM to use**\n",
    "\n",
    "**(T): Set the attidue of the response**\n",
    "\n",
    "**(A): Audience: Idenfiy who the response is for**\n",
    "\n",
    "**(R): Provide the response format**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fbcbf8-0ccc-4fd4-a27d-a27c1ad14ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                    You must complete any incomplete sentence by drawing from your vast\n",
    "                    knowledge about history, literature, science, social science, philosophy, religion, economics, \n",
    "                    sports, etc. Do not make up any responses.\n",
    "                  \"\"\"\n",
    "\n",
    "user_prompts =  [\"On cold winter nights, the wolves in Siberia ...\",\n",
    "                 \"On the day Franklin Benjamin realized his passion for printer, ...\",\n",
    "                 \"During the final World Cup 1998 when France beat Brazil in Paris, ...\",\n",
    "                 \"Issac Newton set under a tree when an apple fell...\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c39358d-f343-4596-bd28-5f36a3ba85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m On cold winter nights, the wolves in Siberia ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m On cold winter nights, the wolves in Siberia gather in packs, their thick fur offering protection from the biting wind. They howl at the moon, their mournful cries echoing across the vast, snow-covered landscape. These ancient creatures, adapted to survive in one of the world's harshest environments, are a testament to the resilience of nature. Their presence in Siberia, a land of extreme cold and isolation, reminds us of the interconnectedness of all living things and the importance of respecting the delicate balance of our planet. \n",
      "\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m On the day Franklin Benjamin realized his passion for printer, ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m On the day Franklin Benjamin realized his passion for printing, he was a young apprentice working in a Boston print shop. The clatter of the printing press and the smell of ink captivated him, sparking a desire to learn the craft. He devoured every scrap of knowledge he could find about printing, from the mechanics of the press to the art of typography.  Benjamin's insatiable curiosity and dedication led him to master the printing trade, a skill that would prove invaluable in his later life as a writer, publisher, and politician. \n",
      "\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m During the final World Cup 1998 when France beat Brazil in Paris, ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m During the final World Cup 1998 when France beat Brazil in Paris, the world witnessed a dramatic and historic moment in football. This victory solidified France's dominance in the sport and marked a defining moment in their national identity.  The iconic image of Zinedine Zidane, the French captain, hoisting the World Cup trophy is etched in the minds of football fans worldwide, a symbol of French triumph and a testament to the team's brilliance.  France's victory also signaled a changing of the guard in world football, ushering in a new era for the French national team and leaving a lasting legacy on the sport. \n",
      "\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m Issac Newton set under a tree when an apple fell...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m Issac Newton set under a tree when an apple fell from its branch, landing squarely on his head. This seemingly mundane event sparked a profound insight in the great physicist: gravity. This pivotal moment led Newton to develop his famous law of universal gravitation, which explained the force that attracts all objects with mass towards one another. His groundbreaking work revolutionized our understanding of the universe, paving the way for future scientific discoveries. \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"\n",
    "    # CONTEXT #\n",
    "    I want to write a complete and cohesive paragpraph for \n",
    "    magazine: Things to know.\n",
    "\n",
    "    #############\n",
    "    \n",
    "    # OBJECTIVE #\n",
    "    Compete the text ```{user_prompt}``` between three backticks to the best \n",
    "    of your acquired knowledge.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # STYLE #\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "    Adhere to a litrary magazine writing style. Keep your sentences succinct and cohesive.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # TONE #\n",
    "    Maintain an editorial tone.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # AUDIENCE #\n",
    "    Our audience are generally curious first to second year college\n",
    "    students.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # RESPONSE #\n",
    "    Finally, keep the response concise and succinct.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    response = response.replace(\"```\", \"\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Prompt:{BOLD_END} {user_prompt}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Answer:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03d54-6200-4664-9a6d-13fe8297e0cb",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "\n",
    "A common task in natural langauge processing is text summiarization. A common use case\n",
    "is summarizing large articles or documents, for a quick and easy-to-absorb summaries.\n",
    "\n",
    "You can instruct LLM to generate the response in a preferable style, and comprehensibility. For example, use simple language aimed for a certain grade level, keep the orginal style of the article, use different sentence sytles (as we have done in few of examples in this notebook and previous one).\n",
    "\n",
    "Let's try a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85736577-b4ee-466e-90c8-a810849fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, philosophy, religion, \n",
    "                    economics, sports, etc. Respond to only answers\n",
    "                    you know of. Do not make up answers\"\"\" \n",
    "                \n",
    "user_prompts = [\n",
    "    \"\"\" The emergence of large language models (LLMs) has marked a significant \n",
    "         breakthrough in natural language processing (NLP), leading to remarkable \n",
    "         advancements in text understanding and generation. \n",
    "         \n",
    "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
    "         to produce hallucinations, resulting in content that is inconsistent with \n",
    "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
    "         to their practical deployment and raises concerns over the reliability of LLMs \n",
    "         in real-world scenarios, which attracts increasing attention to detect and \n",
    "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
    "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
    "         \n",
    "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
    "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
    "         overview of hallucination detection methods and benchmarks. \n",
    "         Additionally, representative approaches designed to mitigate hallucinations \n",
    "         are introduced accordingly. \n",
    "         \n",
    "         Finally, we analyze the challenges that highlight the current limitations and \n",
    "         formulate open questions, aiming to delineate pathways for future  research on \n",
    "         hallucinations in LLMs.\"\"\",\n",
    "    \"\"\"  Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
    "         We explore this broad question through a systematic analysis of GPT on the \n",
    "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
    "         reasoning ability from limited examples in which solutions require some \n",
    "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
    "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
    "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
    "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
    "         reason about them is significantly influenced by the sequential nature of \n",
    "         the text that represents an object within a text encoding of a task. \n",
    "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
    "         consists of one-dimensional (array-like) tasks that are more conducive \n",
    "         to GPT-based reasoning, and where it indeed performs better than on \n",
    "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
    "         representation that is obtained through an external tool, resulting in \n",
    "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
    "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
    "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
    "         simple ARC subset, our study reveals that the use of object-based representations \n",
    "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
    "         data are available at this https URL.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a884cb94-0c4a-40bc-a847-1d5eb354cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m  The emergence of large language models (LLMs) has marked a significant \n",
      "         breakthrough in natural language processing (NLP), leading to remarkable \n",
      "         advancements in text understanding and generation. \n",
      "         \n",
      "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
      "         to produce hallucinations, resulting in content that is inconsistent with \n",
      "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
      "         to their practical deployment and raises concerns over the reliability of LLMs \n",
      "         in real-world scenarios, which attracts increasing attention to detect and \n",
      "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
      "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
      "         \n",
      "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
      "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
      "         overview of hallucination detection methods and benchmarks. \n",
      "         Additionally, representative approaches designed to mitigate hallucinations \n",
      "         are introduced accordingly. \n",
      "         \n",
      "         Finally, we analyze the challenges that highlight the current limitations and \n",
      "         formulate open questions, aiming to delineate pathways for future  research on \n",
      "         hallucinations in LLMs.\n",
      "\n",
      "\u001b[1mSummary  content:\u001b[0m Large language models (LLMs) have revolutionized natural language processing (NLP), but they often generate inaccurate or fabricated information, known as hallucinations. These hallucinations pose significant challenges for deploying LLMs in real-world applications, leading researchers to focus on detecting and mitigating them. This article delves into the intricacies of LLM hallucinations, providing a comprehensive overview of their causes, detection methods, mitigation strategies, and current limitations, ultimately aiming to guide future research in this crucial area. \n",
      "\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m   Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
      "         We explore this broad question through a systematic analysis of GPT on the \n",
      "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
      "         reasoning ability from limited examples in which solutions require some \n",
      "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
      "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
      "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
      "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
      "         reason about them is significantly influenced by the sequential nature of \n",
      "         the text that represents an object within a text encoding of a task. \n",
      "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
      "         consists of one-dimensional (array-like) tasks that are more conducive \n",
      "         to GPT-based reasoning, and where it indeed performs better than on \n",
      "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
      "         representation that is obtained through an external tool, resulting in \n",
      "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
      "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
      "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
      "         simple ARC subset, our study reveals that the use of object-based representations \n",
      "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
      "         data are available at this https URL.\n",
      "\n",
      "\u001b[1mSummary  content:\u001b[0m Can a large language model (LLM) truly reason? While GPT-4, a cutting-edge LLM, excels in language tasks, its abstract reasoning abilities are limited.  Researchers tested GPT-4 on ARC, a benchmark for abstract reasoning, and found it struggled with even the simplest tasks, particularly when visual input was presented in text format. This study reveals that LLMs like GPT-4, despite their impressive capabilities, struggle with visual reasoning and benefit from object-based representations.  The findings suggest that improving LLMs' ability to process and reason about visual information is a crucial step in advancing their cognitive abilities. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "    # CONTEXT #\n",
    "    I want to write a summarize cohesively into at most two paragpraphs for \n",
    "    my magazine: Things to know quickly\n",
    "\n",
    "    #############\n",
    "    \n",
    "    # OBJECTIVE #\n",
    "    Summarize the text ```{user_prompt}``` between three backticks to the best \n",
    "    of your acquired knowledge.\n",
    "\n",
    "     #############\n",
    "\n",
    "    # STYLE #\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "    Adhere to a litrary magazine writing style. Keep your sentences succinct and cohesive.\n",
    "\n",
    "    # TONE #\n",
    "    Maintain the same tone as the text supplied.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # AUDIENCE #\n",
    "    Our audience are generally curious first to second year college\n",
    "    students.\n",
    "\n",
    "    #############\n",
    "\n",
    "     # RESPONSE #\n",
    "    Finally, keep the response concise and succinct\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original content:{BOLD_END} {user_prompt}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Summary  content:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe9c30-bf89-49ee-80c8-c5d260b91914",
   "metadata": {},
   "source": [
    "## Text or information extraction\n",
    "\n",
    "Another natural langauge capability, similar to summarization or text completion, is extracting key idea or infromation from an article, blog, or a paragraph. For example,\n",
    "given a set of text, you can ask LLM to extract key ideas or topics or subjects. Or even\n",
    "better enumerate key takeways for you, saving time if you are in a hurry.\n",
    "\n",
    "Let's see *how-to* do it by first looking at a simple example, and then progressing into a more complex one, all along keepin \n",
    "the [CO-STAR prompting framework](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) in mind.\n",
    "\n",
    "### Task 1: \n",
    " * summarize the product review\n",
    " * extract any information about shipping and packaging for shipping department\n",
    " * classify the sentiment of the review: positive or negative.\n",
    " * use precise, specific prompt to acheive the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21406dcc-e9b1-4028-8281-297ae762b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, social science, \n",
    "philosophy, religion, economics, sports, etc.\n",
    "\"\"\"\n",
    "\n",
    "product_review = \"\"\"I got this Australian Bush Baby with soft fur for my niece's birthday,\n",
    "and she absolutely loves it, carrying it around everywhere. The fur is exceptionally soft,\n",
    "and its adorable face gives off a friendly vibe. While I find it a bit smaller than \n",
    "anticipated for the price, my niece's joy makes it worthwhile. What pleasantly surprised \n",
    "me was the early arrival; it came a day earlier than expected. \n",
    "I appreciated the prompt delivery, and the packaging was secure, ensuring the \n",
    "Bush Baby with soft fur arrived in perfect condition. This allowed me to play with \n",
    "it myself before presenting it to my niece.\n",
    "\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384515f8-a970-421a-86bb-be3ea8800bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "# CONTEXT #\n",
    "In our customer service department, we value customer feedback and want to\n",
    "analyze their reviews by summarizing their review assessing, labeling or categorizing\n",
    "and its idenfitying its sentiment. \n",
    "\n",
    "#############\n",
    "\n",
    "# OBJECTIVE #\n",
    "Your task is to generate a short summary of a product \n",
    "review from an Australian e-commerce site to offer feedback to the \n",
    "shipping deparmtment. Follow the steps below:\n",
    "\n",
    "First, generate a short summary of review below, delimited by triple \n",
    "backticks, in two sentences: a simple and compound sentence. \n",
    "\n",
    "Second, focus on any aspects of packaging or shipping of the product, and label it as \n",
    "\"Shipping Department:\".  \n",
    "\n",
    "Third, indicate if the review is positive or negative, and label it as \"Sentiment:\".\n",
    "Do not provide any preamble, only a simple two words: Positive or negative\n",
    "Review: ```{product_review}``` \n",
    "\n",
    "#############\n",
    "\n",
    "# STYLE #\n",
    "You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "#############\n",
    "\n",
    "# TONE #\n",
    "Maintain a professional tone for internal communications\n",
    "\n",
    "#############\n",
    "\n",
    " # AUDIENCE #\n",
    "Our audience are internal departments in customer success to ensure we can\n",
    "improve our customer service\n",
    "\n",
    "#############\n",
    "\n",
    "# RESPONSE #\n",
    "Finally, keep the response concise and succinct\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0056f55-c3aa-4a4e-bd11-fec330436af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mSummary:\u001b[0m \n",
      "The customer purchased a Bush Baby plush toy for their niece's birthday, and they were very pleased with the product's softness and cuteness.  The customer was pleasantly surprised by the early arrival and appreciated the prompt delivery and secure packaging, which ensured the toy arrived in perfect condition.\n",
      "\n",
      "\n",
      "Shipping Department: The customer was pleased with the prompt delivery and secure packaging, which ensured the toy arrived in perfect condition.\n",
      "\n",
      "Sentiment: Positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\"\"\\n{BOLD_BEGIN}Summary:{BOLD_END} {response.replace(\"```\", \"\")}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb0d62-e2a7-4669-9792-57f20ed95980",
   "metadata": {},
   "source": [
    "### Task 2\n",
    " * Given a passage from an article, extract the main theme of the passage and label it as the `Subjects`, if more than one, separated by comma.\n",
    " * Identify three key takeways and enumerate them in simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cdcd4d4-62c7-4dea-b98a-58070552c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\"\n",
    "            \n",
    "user_prompts = [\"\"\"Isaac Newton sat under a tree when an apple fell, an event that, \n",
    "                according to popular legend, led to his contemplation of the forces\n",
    "                of gravity. Although this story is often regarded as apocryphal or at \n",
    "                least exaggerated, it serves as a powerful symbol of Newton's insight \n",
    "                into the universal law that governs celestial and earthly bodies alike. \n",
    "                His formulation of the law of universal gravitation was revolutionary, \n",
    "                as it provided a mathematical explanation for both the motion of planets \n",
    "                and the phenomena observed on Earth. Newton's work in physics, captured \n",
    "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \n",
    "                groundwork for classical mechanics. His influence extended beyond his own \n",
    "                time, shaping the course of scientific inquiry for centuries to come.\n",
    "                \"\"\"\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e16e2f-14ec-4bfd-9687-294683ad5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m Isaac Newton sat under a tree when an apple fell, an event that, \n",
      "                according to popular legend, led to his contemplation of the forces\n",
      "                of gravity. Although this story is often regarded as apocryphal or at \n",
      "                least exaggerated, it serves as a powerful symbol of Newton's insight \n",
      "                into the universal law that governs celestial and earthly bodies alike. \n",
      "                His formulation of the law of universal gravitation was revolutionary, \n",
      "                as it provided a mathematical explanation for both the motion of planets \n",
      "                and the phenomena observed on Earth. Newton's work in physics, captured \n",
      "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \n",
      "                groundwork for classical mechanics. His influence extended beyond his own \n",
      "                time, shaping the course of scientific inquiry for centuries to come.\n",
      "                \n",
      "\n",
      " \u001b[1mExtracted answers: \u001b[0m ```\n",
      "Isaac Newton sat under a tree when an apple fell, an event that, \n",
      "                according to popular legend, led to his contemplation of the forces\n",
      "                of gravity. Although this story is often regarded as apocryphal or at \n",
      "                least exaggerated, it serves as a powerful symbol of Newton's insight \n",
      "                into the universal law that governs celestial and earthly bodies alike. \n",
      "                His formulation of the law of universal gravitation was revolutionary, \n",
      "                as it provided a mathematical explanation for both the motion of planets \n",
      "                and the phenomena observed on Earth. Newton's work in physics, captured \n",
      "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \n",
      "                groundwork for classical mechanics. His influence extended beyond his own \n",
      "                time, shaping the course of scientific inquiry for centuries to come.\n",
      "                ```\n",
      "\n",
      "**Subject:** Isaac Newton's contributions to physics\n",
      "\n",
      "**Takeaways:**\n",
      "\n",
      "* Newton's law of universal gravitation explained both planetary motion and Earthly phenomena.\n",
      "* His work laid the foundation for classical mechanics.\n",
      "* Newton's influence has continued for centuries. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for text in user_prompts:\n",
    "    prompt = f\"\"\" Given ```{text}``` delimited with triple backticks, identify a single key idea being discussed, \n",
    "    and label its 'Subject'. Next, enumerate at most three takeways. \n",
    "    Use short, simple sentences. \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original content:{BOLD_END} {text}\")\n",
    "    print(f\"\\n {BOLD_BEGIN}Extracted answers: {BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113abb50-6a73-4101-8846-e8f26d85bb9c",
   "metadata": {},
   "source": [
    "Let's try another example to extract more than one subject or topic being\n",
    "discussed in the text, and enumerate three takeways.\n",
    "\n",
    "(Incidentally, I'm reading biography of Benjamin Franklin by Issac Stevenson, and all this seems to align with his career path and passion.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34ceebf-c1b6-495b-8c78-81d2fc45baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stories = [\"\"\"\"\n",
    "'The Printer'\n",
    "    He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
    "Benjamin Franklin had an affinity with print and books throughout his life. \n",
    "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
    "the trade, from typesetting to engraving, learning the latest techniques during his\n",
    "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
    "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
    "Library Company, the first subscription library in the colonies.  As an elder\n",
    "statesman, he even bought type and kept a press during his stay in France. \n",
    "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
    "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
    "Almanack helped to provide Franklin with the financial means to retire from\n",
    "business, retaining a stake in his print shop and founding others throughout the \n",
    "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
    "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
    "journalist and pamphleteer.\n",
    "\n",
    "'Silence Dogood and the New­England Courant'\n",
    "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
    "to begin his own newspaper, launching the New­England Courant in 1721.\n",
    "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
    "paper.  One night he slipped a composition under the door, beginning the series\n",
    "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
    "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
    "little debt to the satire of the London Spectator, the letters represented a \n",
    "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
    "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
    "‘Dogood’ letter appears on the bottom right.\n",
    "\n",
    "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
    "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
    "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
    "and satires on the great and the good, attacking the influential clergyman Cotton\n",
    "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
    "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
    "then continued to publish it under Benjamin’s name to escape a ban on\n",
    "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
    "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1909a1b5-68fa-449c-9d40-0d4494b75b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Story:\u001b[0m \"\n",
      "'The Printer'\n",
      "    He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
      "Benjamin Franklin had an affinity with print and books throughout his life. \n",
      "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
      "the trade, from typesetting to engraving, learning the latest techniques during his\n",
      "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
      "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
      "Library Company, the first subscription library in the colonies.  As an elder\n",
      "statesman, he even bought type and kept a press during his stay in France. \n",
      "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
      "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
      "Almanack helped to provide Franklin with the financial means to retire from\n",
      "business, retaining a stake in his print shop and founding others throughout the \n",
      "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
      "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
      "journalist and pamphleteer.\n",
      "\n",
      "'Silence Dogood and the New­England Courant'\n",
      "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
      "to begin his own newspaper, launching the New­England Courant in 1721.\n",
      "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
      "paper.  One night he slipped a composition under the door, beginning the series\n",
      "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
      "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
      "little debt to the satire of the London Spectator, the letters represented a \n",
      "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
      "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
      "‘Dogood’ letter appears on the bottom right.\n",
      "\n",
      "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
      "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
      "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
      "and satires on the great and the good, attacking the influential clergyman Cotton\n",
      "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
      "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
      "then continued to publish it under Benjamin’s name to escape a ban on\n",
      "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
      "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
      "\n",
      "\n",
      " \u001b[1mExtracted entities:\u001b[0m Subjects: \n",
      "Benjamin Franklin, Printing, Journalism, Literature,  Public Opinion\n",
      "\n",
      "Takeways:\n",
      "- Benjamin Franklin was a printer and journalist who used his skills to shape public opinion.\n",
      "- He was an avid reader and founded the first subscription library in the colonies.\n",
      "- Franklin used satire to criticize the establishment, using the pseudonym \"Silence Dogood\". \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for story in user_stories:\n",
    "    prompt = f\"\"\" Extract five subjects that are being discussed in the \n",
    "                  following text, which is delimited by triple backticks.\n",
    "                  Format your response as a list of subjects \n",
    "                  \"Subjects:\" separate each subject by a comma.\n",
    "                  Make each subject at most two words long, not longer. \n",
    "                  Next, enumerate  as a list three takeways, and label them as \"Takeways:\" \n",
    "                  Use short, simple sentences for your takeways.\n",
    "                  Text sample: '''{story}'''\n",
    "                  \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Story:{BOLD_END} {story}\")\n",
    "    print(f\"\\n {BOLD_BEGIN}Extracted entities:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da3189-e9d0-42c9-9f70-d403df9e0dc5",
   "metadata": {},
   "source": [
    "## Text classification or sentiment analysis\n",
    "\n",
    "Unlike classical or traditional machine learning, where you'll have to do supervised learning to collect data, label it, and train for hours, depending on how much data,classifying text using LLM is simple.\n",
    "\n",
    "In short, you'll have to build an ML model to understand text and classify its sentiments as positive, negative or neutral. \n",
    "\n",
    "This onus task is easily done with LLM via clever prompting. \n",
    "\n",
    "Let's see what I mean in this *how-to* idenfity sentiments in text. But first let's \n",
    "generatre some sentiments as our ground truth, and supply them to LLM to observe if\n",
    "LLM identifies them correctly. This bit is not needed, for I'm just curious.\n",
    "\n",
    "*Positive*: \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\"\n",
    "\n",
    "*Negative*: \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\"\n",
    "\n",
    "*Neutral*: \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\"\n",
    "\n",
    "*Negative*: \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\"\n",
    "\n",
    "*Neutral*: \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\"\n",
    "\n",
    "*Positive*: \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\"\n",
    "\n",
    "*Negative*: \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\"\n",
    "\n",
    "*Neutral*: \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\"\n",
    "\n",
    "*Positive*: \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\"\n",
    "\n",
    "*Negative*: \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\"\n",
    "\n",
    "*Neutral*: \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\"\n",
    "\n",
    "*Negative*: \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\"\n",
    "\n",
    "*Neutral*: \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26fba25e-e40b-40fc-84b5-0a86df748b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a prominent critic of landscapes, architecture, cities, movies, songs, \n",
    "                    entertainment, and a cultural ombudsman. \"\"\"\n",
    "\n",
    "user_sentiments = [ \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\",\n",
    "                    \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\",\n",
    "                    \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\",\n",
    "                    \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\",\n",
    "                    \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\",\n",
    "                    \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\",\n",
    "                    \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\",\n",
    "                    \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\",\n",
    "                    \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\",\n",
    "                    \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\",\n",
    "                    \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\",\n",
    "                    \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\",\n",
    "                    \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\",\n",
    "                    \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\",\n",
    "                    \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\",\n",
    "                    \"xxxyyyzzz was curious and dubious\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bae549c-fa32-46e8-af19-83f923222e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m negative \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m negative \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m neutral \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m negative \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m neutral \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m negative \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m negative \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive \n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m xxxyyyzzz was curious and dubious\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m neutral \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for user_sentiment in user_sentiments:\n",
    "    prompt = f\"\"\"Classify the sentiment in the ```{user_sentiment}`` which is delimited \n",
    "        with triple backticks? Classify the given text into single label as \n",
    "        neutral, negative or positive. Do not expand on your response. \n",
    "        Use single words: positive, negative, neutral\n",
    "        If you cannot classify do not guess, do not ask for more info,\n",
    "        just classify as NA.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Sentiment:{BOLD_END} {user_sentiment}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Label    :{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f520fec-af04-4b97-8e66-3187e34b5566",
   "metadata": {},
   "source": [
    "## Text categorization\n",
    "Like sentiment analysis, given a query, an LLM can identify from its context how to classify and route customer queries to respective departments. Also, note that LLM can detect foul language and respond politely. Text categorization can be employed to automate customer on-line queries.\n",
    "\n",
    "Let's look at how we can achieve that with smart and deliberate prompting.\n",
    "\n",
    "<img src=\"./images/category_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75b9307f-a2b3-4393-8e5a-5d7af520ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a smart and helful Assistant who can route customer queries to \n",
    "                    respective customer service departments.\n",
    "                    \"\"\"\n",
    "\n",
    "customer_queries = [\"\"\"My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\"\"\",\n",
    "                    \"\"\"I just moved into town, and I need Internet service\"\"\",\n",
    "                    \"\"\"Why does my bill include an extra $20 a month for cable TV when I don't use a television?\"\"\",\n",
    "                    \"\"\"I need to change my user name and password since someone is using my credentials. I cannot access my account.\"\"\",\n",
    "                    \"\"\"What days this week are we having a general upgrades to the cable models?\"\"\",\n",
    "                    \"\"\"What day is the best day to call customer service so that I can avoid talking to a bot!\"\"\",\n",
    "                    \"\"\"Your company did a bad job for internet service!\"\"\",\n",
    "                    \"\"\"I hate your worthless services. Cancel my stupid account or else I'll sue you!\"\"\"\n",
    "                   ]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36fe82a0-9486-4e8c-b573-3bb71d7a71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m Technical support \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I just moved into town, and I need Internet service\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m New Customer \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m Why does my bill include an extra $20 a month for cable TV when I don't use a television?\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m Billing \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I need to change my user name and password since someone is using my credentials. I cannot access my account.\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m Account Management \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m What days this week are we having a general upgrades to the cable models?\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m General inquiry \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m What day is the best day to call customer service so that I can avoid talking to a bot!\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m General inquiry \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m Your company did a bad job for internet service!\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m General inquiry \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I hate your worthless services. Cancel my stupid account or else I'll sue you!\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m Account Management \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for query in customer_queries:\n",
    "    prompt = f\"\"\" \n",
    "    We are an Internet Service provider in a big metropolitan city. We want to \n",
    "    improve our customer service support by building a routing system so\n",
    "    that customer inquiries are routed responsively, respectfully, and actively to\n",
    "    appropriate company departments. Your task is to classify each customer's {query} \n",
    "    into one of the the following five categories:\n",
    "    1. Technical support\n",
    "    2. Billing \n",
    "    3. Account Management\n",
    "    4. New Customer  \n",
    "    5. General inquiry\n",
    "    \n",
    "    Do not expand or explain your response. Do not include backticks or quotes \n",
    "    in your response. Do not choose more than one category in your response from these categories: \n",
    "    Technical support, Billing, Account Management, New Customer, General inquiry\n",
    "    Do not include the {query} in your response.\n",
    "    If you can't classify the {query}, default to \"General inquiry.\"\n",
    "    If customer {query} uses a foul language, then respond with \n",
    "    \"No need for foul language. Please be respectful.\"\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Query:{BOLD_END} {query}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Route to:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05333b92-c3fb-4341-b59d-82eeb7a65071",
   "metadata": {},
   "source": [
    "## Text transation and transformation\n",
    "\n",
    "Language translation by far is the most common use case for natural language processing. \n",
    "We have seen its early uses in Google translation, but with the emergence of multi-lingual LLMs, this task is simply achieved by exact prompting. \n",
    "\n",
    "In this section, we'll explore tasks in how to use LLMs for text translations, langugage identication, text transformation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "### Task 1:\n",
    " * Given an English text, translate into French, Spanish, and German.\n",
    " * Given a foreign language text, idenfify the language, and translate to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e9dcecd-8c00-45d6-af45-af19ee7bffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content= \"\"\"You are a world reknowned supreme lingiust and a universal translator. You are a polglot, and fluently speak many global languages\"\"\"\n",
    "\n",
    "english_texts = [\"\"\" Welcome to New York for the United Nations General Council Meeting. Today\n",
    "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
    "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
    "and promote deterence, detente, and discussion.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad8986d5-3ade-4264-a29b-77dbf7b0ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mEnglish Text:\u001b[0m  Welcome to New York for the United Nations General Council Meeting. Today\n",
      "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
      "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
      "and promote deterence, detente, and discussion.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0mHere are the translations of the text into Spanish, French, German, and Mandarin:\n",
      "\n",
      "**Spanish:**\n",
      "```\n",
      "Bienvenidos a Nueva York para la reunión del Consejo General de las Naciones Unidas. Hoy\n",
      "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
      "Pero lo que es más importante, queremos abordar cómo podemos mitigar el conflicto global con la conversación\n",
      "y promover la disuasión, la distensión y el diálogo.\n",
      "```\n",
      "\n",
      "**French:**\n",
      "```\n",
      "Bienvenue à New York pour la réunion du Conseil général des Nations unies. Aujourd'hui\n",
      "est un jour spécial pour célébrer toutes nos réalisations depuis la formation de cet institut mondial.\n",
      "Mais plus important encore, nous voulons aborder la manière dont nous pouvons atténuer les conflits mondiaux par la conversation\n",
      "et promouvoir la dissuasion, la détente et le dialogue.\n",
      "```\n",
      "\n",
      "**German:**\n",
      "```\n",
      "Willkommen in New York zur Sitzung des Generalkonsels der Vereinten Nationen. Heute\n",
      "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
      "Aber noch wichtiger ist es, dass wir uns damit auseinandersetzen, wie wir globale Konflikte durch Gespräche\n",
      "mindern und Abschreckung, Entspannung und Diskussion fördern können.\n",
      "```\n",
      "\n",
      "**Mandarin:**\n",
      "```\n",
      "欢迎来到纽约参加联合国大会理事会会议。今天\n",
      "是我们庆祝这个全球机构成立以来所有成就的特殊日子。\n",
      "但更重要的是，我们希望探讨如何通过对话缓解全球冲突\n",
      "并促进威慑、缓和和讨论。\n",
      "``` \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for english_text in english_texts:\n",
    "    prompt = f\"\"\"\"Given an English text in triple ticks '''{english_text}'''. Translate into\n",
    "three languases: Spanish, French, German, and Mandarin. \n",
    "Label each translation with the langauge Name: followed by translation on a seperate line.\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}English Text:{BOLD_END} {english_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Translation: {BOLD_END}{response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dae09d-5198-42a6-896b-347f260fe3eb",
   "metadata": {},
   "source": [
    "Given a foreing language, identify the language and translate into English.\n",
    "\n",
    "This is the reverse of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a366e171-38b6-4d8d-928a-a36ec0137a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_texts = [\"\"\"Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
    "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
    "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
    "y promover la disuasión, la distensión y el diálogo.\"\"\",\n",
    "            \"\"\"Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
    "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
    "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
    "und Abschreckung, Entspannung und Diskussion fördern.\"\"\",\n",
    "                  \"\"\"Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
    "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
    "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
    "et promouvoir la dissuasion, la détente et la discussion.\"\"\",\n",
    "                  \"\"\"欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
    "\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44a86628-4641-4283-8bba-9d2961451915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
      "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
      "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
      "y promover la disuasión, la distensión y el diálogo.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m ```\n",
      "Language Name: Spanish\n",
      "English translation: Welcome to New York for the General Assembly of the United Nations. Today is a special day to celebrate all our achievements since the formation of this global institution. But more importantly, we want to address how we can mitigate global conflict through dialogue and promote deterrence, détente, and dialogue.\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
      "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
      "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
      "und Abschreckung, Entspannung und Diskussion fördern.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m **Language Name:** German\n",
      "\n",
      "**English Translation:** \n",
      "Welcome to New York for the session of the United Nations General Assembly. Today is a special day for us to celebrate all our achievements since the founding of this global institution. But more importantly, we want to address how we can mitigate global conflicts through dialogue and promote deterrence, détente, and discussion. \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
      "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
      "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
      "et promouvoir la dissuasion, la détente et la discussion.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m Language Name: French\n",
      "\n",
      "English translation: \"Welcome to New York for the meeting of the United Nations General Council. Today,\n",
      "it's a special day for us to celebrate all our achievements since the formation of this global institution.\n",
      "But more importantly, we want to address how we can mitigate global conflicts through conversation\n",
      "and promote deterrence, détente, and discussion.\" \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m 欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
      "\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m ```\n",
      "Language Name: Chinese (Simplified)\n",
      "English Translation: Welcome to New York for the United Nations General Assembly. Today is a special day for us, as we celebrate all the achievements made since the founding of this global institution. But more importantly, we want to discuss how we can alleviate global conflicts through dialogue and promote restraint, de-escalation, and discussion.\n",
      "``` \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for language_text in languages_texts:\n",
    "    prompt = f\"\"\"\"Given a language text in triple ticks '''{language_text}'''. Idenfity\n",
    "    the language with the langauge Name: followed by an English translation on a seperate line, labeled as English translation:\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN} Language Text: {BOLD_END} {language_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Translation: {BOLD_END} {response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8740e21-ea45-4b38-a0f7-753ef48a02aa",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    " * Given an English text, proof read it and correct any grammatical and usage errors.\n",
    " * Given a Pirate text, correct its tone to standard English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a31e6bb8-83dd-4f0a-9036-a58e305e7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a fastidious grammarian. You can proofread any English text and convert to \n",
    "its grammtical correct and usage form.\"\"\"\n",
    "\n",
    "bad_english_texts = [\"\"\"I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\"\"\",\n",
    "                     \"\"\"Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\"\"\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e4f0a39-e951-4e69-b547-cb969ea8250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m \"I don't know anything about those big words and grammar rules. My friend and I were talking, and he disagreed with me. We'll never figure it out, I guess. His dog doesn't listen well, always running around and not coming when you call.\" \n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m Here is the corrected text:\n",
      "\n",
      "\"Yesterday, we were at the park, and the kids were playing. She doesn't like the way they acted, but I don't have any problem with it. We saw a movie last night, and it was good, but my sister hasn't seen it yet. Those books on the shelf aren't interesting to me.\" \n",
      "\n",
      "Here's a breakdown of the changes:\n",
      "\n",
      "* **\"was\" to \"were\":**  \"We\" is a plural subject, so it needs the plural verb \"were.\"\n",
      "* **\"them\" to \"the\":**  \"Them\" is a pronoun used for objects, not subjects. \"The\" is the correct article here. \n",
      "* **\"was\" to \"were\":**  Again, \"kids\" is plural, so it needs the plural verb \"were.\"\n",
      "* **\"don't like\" to \"doesn't like\":**  \"She\" is singular, so the verb needs to be singular as well.\n",
      "* **\"got no\" to \"have any\":**  This phrase is more standard in formal writing.\n",
      "* **\"seen\" to \"saw\":**  \"Saw\" is the past tense of \"see.\" \n",
      "* **\"don't seen\" to \"hasn't seen\":**  \"She\" is singular, so the verb needs to be singular.\n",
      "* **\"them\" to \"those\":** \"Those\" is the correct demonstrative pronoun to refer to specific books.\n",
      "* **\"ain't\" to \"aren't\":**  \"Aren't\" is the standard contraction for \"are not.\" \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for bad_english_text in bad_english_texts:\n",
    "    prompt = f\"\"\"\"Proofread and correct the text provided in triple ticks '''{bad_english_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Text:{BOLD_END} {bad_english_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Corrected  Text:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01c28033-8175-427b-93d2-69db740060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_texts = [\"\"\"Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\"\"\"\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f09b26f1-b370-4cd3-9079-b5b78df502d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m I don't know anything about those fancy words and grammatical rules. My friend and I are talking, but he doesn't agree with me. We're never going to figure it out, I guess. His dog doesn't listen well, always running around and not coming when you call. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "for pirate_text in pirate_texts:\n",
    "    prompt = f\"\"\"\"Convert the Pirate text provided in triple ticks '''{pirate_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage, dropping all Pirate greetings.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Text:{BOLD_END} {pirate_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Corrected  Text:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e48460-00a6-4a7f-9e54-b1e25e00860d",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "* Given some text in a particular format, convert it into JSON format.\n",
    "* For example, we LLM to producce names of three top shoes, but we want them it product and its items in JSON format. This JSON format can be fed downstream into another application that may process it.\n",
    "\n",
    "Let's have go at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab5b7a40-5d26-4bb0-816e-08f04462d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You have knowledge of all sporting goods and will provide knowledge answers\n",
    "to queries about sporting goods.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f77a87f-cf8a-486a-8c43-38a9e5f0c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Google Gemini ...\n",
      "\n",
      "\n",
      " \u001b[1mJSON response:\u001b[0m ```json\n",
      "{\n",
      "  \"products\": [\n",
      "    {\n",
      "      \"Brand\": \"Nike\",\n",
      "      \"Description\": \"Nike Air Max 270 - Sleek and stylish running shoes with a large air unit for maximum cushioning and comfort.\",\n",
      "      \"Size\": \"8-13\",\n",
      "      \"Gender\": \"Unisex\",\n",
      "      \"Price\": \"$160\",\n",
      "      \"Reviews\": [\n",
      "        {\n",
      "          \"Rating\": 5,\n",
      "          \"Comment\": \"These shoes are amazing! They're so comfortable and stylish. I get compliments on them all the time.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 4,\n",
      "          \"Comment\": \"Great for running and everyday wear. The cushioning is incredible.  Only downside is the price.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 3,\n",
      "          \"Comment\": \"They look great, but I've found they're not the best for high-impact activities.  Good for walking though.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"Adidas\",\n",
      "      \"Description\": \"Adidas Ultraboost 22 - Lightweight and responsive running shoes with a Boost midsole for energy return and a breathable Primeknit upper.\",\n",
      "      \"Size\": \"7-12\",\n",
      "      \"Gender\": \"Unisex\",\n",
      "      \"Price\": \"$180\",\n",
      "      \"Reviews\": [\n",
      "        {\n",
      "          \"Rating\": 5,\n",
      "          \"Comment\": \"These are my go-to running shoes!  Love the fit and feel.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 4,\n",
      "          \"Comment\": \"Really comfortable and supportive.  Slightly pricey, but worth the investment.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 3,\n",
      "          \"Comment\": \"They run a little small, so order a half size up.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"New Balance\",\n",
      "      \"Description\": \"New Balance Fresh Foam X 880 v12 -  Comfortable and versatile shoes with a plush Fresh Foam X midsole for a smooth ride and a breathable upper.\",\n",
      "      \"Size\": \"6-13\",\n",
      "      \"Gender\": \"Male\",\n",
      "      \"Price\": \"$140\",\n",
      "      \"Reviews\": [\n",
      "        {\n",
      "          \"Rating\": 5,\n",
      "          \"Comment\": \"Amazing for walking and long runs.  I can wear these for hours without any pain.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 4,\n",
      "          \"Comment\": \"Great value for the price.  Super comfortable and well-made.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 3,\n",
      "          \"Comment\": \"The design is a little boring, but they're functional.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"Brooks\",\n",
      "      \"Description\": \"Brooks Ghost 14 - Durable and responsive running shoes with a soft and plush DNA LOFT midsole and a breathable engineered mesh upper.\",\n",
      "      \"Size\": \"5-12\",\n",
      "      \"Gender\": \"Female\",\n",
      "      \"Price\": \"$130\",\n",
      "      \"Reviews\": [\n",
      "        {\n",
      "          \"Rating\": 5,\n",
      "          \"Comment\": \"These are the best running shoes I've ever owned!  They're so comfortable and supportive.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 4,\n",
      "          \"Comment\": \"Really good for long runs.  They're well-cushioned and don't feel too bulky.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 3,\n",
      "          \"Comment\": \"They're a bit pricey, but they seem to be holding up well.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"ASICS\",\n",
      "      \"Description\": \"ASICS GEL-Nimbus 24 -  Lightweight and cushioned running shoes with a GEL technology midsole for shock absorption and a breathable engineered mesh upper.\",\n",
      "      \"Size\": \"6-13\",\n",
      "      \"Gender\": \"Unisex\",\n",
      "      \"Price\": \"$160\",\n",
      "      \"Reviews\": [\n",
      "        {\n",
      "          \"Rating\": 5,\n",
      "          \"Comment\": \"These shoes are perfect for running on pavement.  They're super comfortable and provide great support.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 4,\n",
      "          \"Comment\": \"They run a little wide, but I've found they're great for my high arches.\"\n",
      "        },\n",
      "        {\n",
      "          \"Rating\": 3,\n",
      "          \"Comment\": \"The color options are a bit limited.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: Google Gemini ...\\n\")\n",
    "prompt = f\"\"\"Generate five distinct products on training shoes. Generate products and format them all as a \n",
    "            in a single JSON object. For each product, the JSON object should contain items: Brand, Description, Size, Gender: Male \n",
    "            or Female or Unisex, Price, and at least three customer reviews as Review \n",
    "            item\"\"\"\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\\n {BOLD_BEGIN}JSON response:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496b00-0a1d-4a57-9783-11f2dcf09c5a",
   "metadata": {},
   "source": [
    "## Simple and complex reasoning \n",
    "\n",
    "An import characteristic of LLM is that it's not only general respository of compressed\n",
    "knowledge garned from large corpus of text, but can be employed as a simple and complex reasoning engine. With use of precise prompt, you can instruct LLM to think trough a problem in a step by step fashion.\n",
    "\n",
    "Let's look at some tasks as examples.\n",
    " * **Task 1**: given a list of numbers identify the prime numbers, add the prime numbers and check if the sum is even or odd.\n",
    " * **Task 2**: given an hourly rate of wages, compute your yearly income if you work 30 hours a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47be9101-2af8-4074-a970-b6cdadc692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a reasoning engine. Given a problem think through the problem logically\n",
    "in a step by step manner.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c0b6b93-5218-4239-9db4-674e6b8dbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 prompt\n",
    "prime_number_prompt = f\"\"\"given a list of numbers 1,2,3,4,5,7,8, 11,13,17,19,23,24,29 identify the prime numbers, add the prime numbers, \n",
    "and check if the sum is even or odd. Explain each step how you solved the problem\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f0bd7a7-9c8b-4c97-85b3-8f83a0ca61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2 prompt\n",
    "hourly_wages_prompt = f\"\"\"If my hourly rate is $117.79 per hour and 30 hours a week, what\n",
    "is my yearly income? Break the problem into simple steps and explain in each step how you arrive \n",
    "to the answer. If you don't know, simple say I don't know. Do not make up answers\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36694e-5634-4aee-9a00-e677da6baa5d",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4ecb495-ee6f-4033-8fa7-7c364d79ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer: \u001b[0mHere's how we can identify the prime numbers, add them, and determine if the sum is even or odd:\n",
      "\n",
      "**1. Identifying Prime Numbers:**\n",
      "\n",
      "* **Definition:** A prime number is a whole number greater than 1 that has only two divisors: 1 and itself. \n",
      "* **Checking the list:**\n",
      "    * **1:**  Not a prime number (it only has one divisor: 1).\n",
      "    * **2:** Prime number (divisors: 1 and 2).\n",
      "    * **3:** Prime number (divisors: 1 and 3).\n",
      "    * **4:** Not a prime number (divisors: 1, 2, and 4).\n",
      "    * **5:** Prime number (divisors: 1 and 5).\n",
      "    * **7:** Prime number (divisors: 1 and 7).\n",
      "    * **8:** Not a prime number (divisors: 1, 2, 4, and 8).\n",
      "    * **11:** Prime number (divisors: 1 and 11).\n",
      "    * **13:** Prime number (divisors: 1 and 13).\n",
      "    * **17:** Prime number (divisors: 1 and 17).\n",
      "    * **19:** Prime number (divisors: 1 and 19).\n",
      "    * **23:** Prime number (divisors: 1 and 23).\n",
      "    * **24:** Not a prime number (divisors: 1, 2, 3, 4, 6, 8, 12, and 24).\n",
      "    * **29:** Prime number (divisors: 1 and 29).\n",
      "\n",
      "**2. Adding the Prime Numbers:**\n",
      "\n",
      "* Prime numbers from the list: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29\n",
      "* Sum = 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 = 139\n",
      "\n",
      "**3. Determining Even or Odd:**\n",
      "\n",
      "* A number is even if it is divisible by 2. \n",
      "* 139 is not divisible by 2. \n",
      "* Therefore, the sum of the prime numbers is **odd**. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, prime_number_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd2c6e-bfa7-45cc-804d-acaf4797f8f3",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5651b79b-997e-4524-b17b-14f413e850a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer: \u001b[0mHere's how to calculate your yearly income:\n",
      "\n",
      "**Step 1: Calculate Weekly Earnings**\n",
      "\n",
      "* Multiply your hourly rate by the number of hours you work per week: $117.79/hour * 30 hours/week = $3533.70/week\n",
      "\n",
      "**Step 2: Calculate Yearly Earnings**\n",
      "\n",
      "* Multiply your weekly earnings by the number of weeks in a year (52): $3533.70/week * 52 weeks/year = $183,748.40/year\n",
      "\n",
      "**Therefore, your yearly income would be $183,748.40.** \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, hourly_wages_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a5da1-986a-4682-a672-8c213eb40be5",
   "metadata": {},
   "source": [
    "## Code generation\n",
    "\n",
    "Language models like ChatGPT and Llama 2 are really good at generating code. Copilot on GitHub is a cool example of this. You can do lots of different code tasks just by asking in a smart way. Let's check out a few examples to see how it's helpful.\n",
    "\n",
    "#### Task 1\n",
    " * Generate Python code to compute the value of PI using Ray distributed framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de3ad4ed-e28e-44a7-8a33-11136f6334d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a supreme CoPilot for a developer. Given a task you can\n",
    "generate code for that task.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9a85173-dbce-4bf6-b004-7e368a5ccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_prompt=\"\"\"Generate Python code to compute the value of PI using Ray \n",
    "distributed framework API. Use the Monte Carlo method to compute the value of PI.\n",
    "Include in-line comments explaining the code\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60e2b04a-9f0c-450f-aeda-8e6ece5b0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mGenerated Python code:\u001b[0m```python\n",
      "import ray\n",
      "import random\n",
      "\n",
      "# Initialize Ray\n",
      "ray.init()\n",
      "\n",
      "# Define a function to simulate a random point within a unit square\n",
      "@ray.remote\n",
      "def simulate_point():\n",
      "  \"\"\"Simulates a random point within a unit square.\"\"\"\n",
      "  x = random.uniform(0, 1)\n",
      "  y = random.uniform(0, 1)\n",
      "  return x, y\n",
      "\n",
      "# Define a function to calculate PI using the Monte Carlo method\n",
      "@ray.remote\n",
      "def calculate_pi(num_points):\n",
      "  \"\"\"Calculates PI using the Monte Carlo method.\"\"\"\n",
      "  inside_circle = 0\n",
      "  for _ in range(num_points):\n",
      "    x, y = simulate_point.remote()\n",
      "    # Check if the point lies within the unit circle\n",
      "    if x**2 + y**2 <= 1:\n",
      "      inside_circle += 1\n",
      "  return inside_circle\n",
      "\n",
      "# Number of points to simulate\n",
      "num_points = 1000000\n",
      "\n",
      "# Distribute the simulations across multiple workers\n",
      "results = [calculate_pi.remote(num_points // 100) for _ in range(100)]\n",
      "\n",
      "# Collect the results from the workers\n",
      "inside_counts = ray.get(results)\n",
      "\n",
      "# Calculate the total number of points inside the circle\n",
      "total_inside_circle = sum(inside_counts)\n",
      "\n",
      "# Calculate PI using the Monte Carlo formula\n",
      "pi_estimate = 4 * (total_inside_circle / num_points)\n",
      "\n",
      "# Print the estimated value of PI\n",
      "print(\"Estimated value of PI:\", pi_estimate)\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **Initialization:** The code starts by initializing Ray using `ray.init()`. This creates the necessary infrastructure for distributed execution.\n",
      "2. **`simulate_point` Function:** This function simulates a random point within a unit square. It generates random x and y coordinates between 0 and 1 using `random.uniform()`.\n",
      "3. **`calculate_pi` Function:** This function uses the Monte Carlo method to estimate PI.\n",
      "   - It takes the total number of points (`num_points`) as input.\n",
      "   - It simulates a specified number of points using `simulate_point.remote()` and checks if each point lies within the unit circle (using `x**2 + y**2 <= 1`).\n",
      "   - The count of points inside the circle is accumulated.\n",
      "   - The function returns the count of points inside the circle.\n",
      "4. **Distributed Simulations:**\n",
      "   - The code divides the total number of simulations (`num_points`) into smaller batches (100 batches in this case) to distribute the workload across multiple workers.\n",
      "   - It uses a list comprehension to create a list of `calculate_pi.remote()` calls, each with a portion of the total points.\n",
      "5. **Result Collection:**\n",
      "   - `ray.get(results)` collects the results from all the remote tasks, which are the counts of points inside the circle from each worker.\n",
      "6. **PI Calculation:**\n",
      "   - The code sums up the counts from all workers (`total_inside_circle`) to get the total number of points inside the circle.\n",
      "   - It then calculates the estimated value of PI using the formula: `4 * (total_inside_circle / num_points)`.\n",
      "7. **Output:** Finally, the estimated value of PI is printed.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "- **Ray Tasks:** The `@ray.remote` decorator defines functions that can be executed on remote workers.\n",
      "- **Task Distribution:** The code divides the work into smaller tasks and distributes them to different workers, making use of Ray's distributed execution capabilities.\n",
      "- **Result Aggregation:** `ray.get()` efficiently gathers results from all the workers, enabling a unified calculation of PI.\n",
      "\n",
      "This code provides a straightforward example of using Ray to perform distributed computations for estimating the value of PI using the Monte Carlo method.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, python_code_prompt)\n",
    "\n",
    "print(f\"\\n{BOLD_BEGIN}Generated Python code:{BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7fdc8-7a19-4a1a-b119-7a0bf0b3ae0f",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    " * Given SQL schema tables, generate an SQL query \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "585f372c-fe37-43b4-9299-c5708d1be06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_code_prompt=\"\"\"Given the following SQL schema for tables\n",
    "Table clicks, columns = [target_url, orig_url, user_id, clicks]\n",
    "Table users, columns = [user_id, f_name, l_name, e_mail, company, title], generate\n",
    "an SQL query that computes in the descening order of all the clicks. Also, for\n",
    "each user_id, list the f_name, l_name, company, and title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "351b78d7-c78b-4a1b-946b-8a2abd17efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mGenerated SQL code: \u001b[0m```sql\n",
      "SELECT\n",
      "  c.user_id,\n",
      "  u.f_name,\n",
      "  u.l_name,\n",
      "  u.company,\n",
      "  u.title,\n",
      "  SUM(c.clicks) AS total_clicks\n",
      "FROM clicks c\n",
      "JOIN users u ON c.user_id = u.user_id\n",
      "GROUP BY c.user_id, u.f_name, u.l_name, u.company, u.title\n",
      "ORDER BY total_clicks DESC;\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **`SELECT` Clause:**\n",
      "   - Selects the following columns:\n",
      "     - `c.user_id`: The user ID from the `clicks` table.\n",
      "     - `u.f_name`: The first name from the `users` table.\n",
      "     - `u.l_name`: The last name from the `users` table.\n",
      "     - `u.company`: The company name from the `users` table.\n",
      "     - `u.title`: The job title from the `users` table.\n",
      "     - `SUM(c.clicks) AS total_clicks`: Calculates the sum of clicks for each user and aliases it as `total_clicks`.\n",
      "\n",
      "2. **`FROM` Clause:**\n",
      "   - Specifies the tables involved: `clicks` (aliased as `c`) and `users` (aliased as `u`).\n",
      "\n",
      "3. **`JOIN` Clause:**\n",
      "   - Uses an inner join to connect the two tables based on the common column `user_id`.\n",
      "\n",
      "4. **`GROUP BY` Clause:**\n",
      "   - Groups the results by `user_id`, `f_name`, `l_name`, `company`, and `title`. This ensures that clicks are aggregated correctly for each unique user.\n",
      "\n",
      "5. **`ORDER BY` Clause:**\n",
      "   - Sorts the results in descending order of `total_clicks` to show the users with the most clicks first.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, sql_code_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Generated SQL code: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546337d-b9a4-40db-92dd-8cdce63c6979",
   "metadata": {},
   "source": [
    "## All this is amazing! 😜 Feel the wizardy prompt power 🧙‍♀️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
