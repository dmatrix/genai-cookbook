{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc77cf2-1739-4661-8ef1-858850e48166",
   "metadata": {},
   "source": [
    "## Few-shot learning prompting\n",
    "\n",
    "Few-shot learning in the context of prompting involves teaching a language model to perform a task by showing it only a small number of examples. Essentially, you provide a few samples of the input along with the desired output, and the model learns to generalize from these examples to new, similar tasks. This method is useful for adapting the model to specific tasks without extensive training data.\n",
    "\n",
    "This approach allows LLMs to adapt to a wide variety of tasks without extensive retraining or fine-tuning on large datasets.\n",
    "\n",
    "Let's have a go at few exmaples of few-shot learning prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9a2f4-4e02-47fa-8ddb-62437c52acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b71f4-54d8-486a-92c1-9284c278ec7e",
   "metadata": {},
   "source": [
    "Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a9d77-c25d-4ee8-8b4b-eaf76c54ddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba822ab-7a73-4968-a73d-fd629324f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the OpenAI client, which can be used transparently with Anyscale Endpoints too\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a86c21-a74a-4415-83f1-8942b710cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to send and fetch response\n",
    "\n",
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb6d45-214c-4fb2-986f-9e1dee398608",
   "metadata": {},
   "source": [
    "## Example 1: Recipe Generation\n",
    "An example use case for few-shot learning is to provide couple of examples of recipies that the model can learn from and generalize. Using \n",
    "what it has learned as couple of in-context examples, it can generate a response for its subsequent prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4740f-c9b6-4f55-b1bd-e1dba3828b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are supreme repository of knowledge, including all \n",
    "exotic culnary dishes across the globe.\"\"\"\n",
    "\n",
    "few_shot_recipe_prompt = \"\"\"Recipe for simple cheese omlette. \n",
    "Ingridients: \n",
    "1. 3 large eggs\n",
    "2. 1/4 cup shredded cheddar cheese\n",
    "3. Salt and pepper to taste\n",
    "4. 1 tablespoon butter\n",
    "Directions:\n",
    "1. Crack the eggs into a bowl, add salt, and pepper, then beat them until well mixed.\n",
    "2. Heat the butter in a non-stick pan over medium heat until it melts and coats the pan.\n",
    "3. Pour the beaten eggs into the pan, swirling them to cover the bottom evenly.\n",
    "4. Sprinkle the shredded cheese over one half of the eggs.\n",
    "5. Once the edges are set, fold the omelet in half with a spatula, covering the cheese. Cook for another minute until the cheese melts. Enjoy your delicious cheese omelet!\n",
    "\n",
    "Generate a recipe for choclate pancakes:\n",
    "Ingridients:\n",
    "Directions:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b06b76-e125-4d67-a997-ee48636d00d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simple recipe for chocolate pancakes:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup all-purpose flour\n",
      "- 2 tablespoons cocoa powder\n",
      "- 2 tablespoons sugar\n",
      "- 1/4 teaspoon salt\n",
      "- 2 teaspoons baking powder\n",
      "- 1 large egg\n",
      "- 1 cup milk\n",
      "- 2 tablespoons unsalted butter, melted\n",
      "- 1/2 teaspoon pure vanilla extract\n",
      "- 1/4 cup semi-sweet chocolate chips (optional for added chocolatey goodness)\n",
      "- Butter or oil for cooking\n",
      "- Maple syrup, whipped cream, or your choice of toppings\n",
      "\n",
      "Directions:\n",
      "1. In a large mixing bowl, whisk together the flour, cocoa powder, sugar, salt, and baking powder to combine and break up any lumps.\n",
      "2. In another bowl, beat the egg and then add the milk, melted butter, and vanilla extract. Stir to combine.\n",
      "3. Pour the wet ingredients into the dry ingredients, mixing gently until just combined. Be careful not to overmix; a few lumps are okay. If the batter is too thick, you can add a little more milk to reach the desired consistency.\n",
      "4. Fold in the chocolate chips if using.\n",
      "5. Heat a non-stick skillet or griddle over medium heat. Brush with a small amount of butter or oil.\n",
      "6. For each pancake, ladle about 1/4 cup of batter onto the griddle. Cook until bubbles form on the surface and the edges look set, about 2-3 minutes.\n",
      "7. Flip the pancakes carefully and cook for another 2 minutes on the other side, or until cooked through.\n",
      "8. Repeat with the remaining batter, adding more butter or oil to the skillet as needed.\n",
      "9. Serve hot with your favorite toppings like maple syrup, more chocolate chips, fruit, whipped cream, or a dusting of powdered sugar.\n",
      "\n",
      "Enjoy your homemade chocolate pancakes!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, few_shot_recipe_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2dfdef-27a1-42ad-bdcd-d9464f7f4f7a",
   "metadata": {},
   "source": [
    "### Example 2: Code Generation and Scripting\n",
    "\n",
    "Using few-shot learning, we can provide in-context examples of how to write a script that the model can generalize and generate any script \n",
    "in the language its trained on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe55bec-75cb-4f48-8c8e-d7bd7947936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are supreme repository of knowledge, and assistant\n",
    "code Co-pilot for developer to assist them in generating sample code, inclding\n",
    "in langauges such as Python, JavaScript, Java, C, C++, and shell script.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_code_gen_prompt = \"\"\"\n",
    "Python code to compute Fibonacci series:\n",
    "\n",
    "Problem: Compute Fibonnacci series\n",
    "Language: Python\n",
    "Code: \n",
    "def fibonacci(n):\n",
    "    fib_series = [0, 1]\n",
    "    while fib_series[-1] + fib_series[-2] <= n:\n",
    "        fib_series.append(fib_series[-1] + fib_series[-2])\n",
    "    return fib_series\n",
    "\n",
    "# Example: Compute Fibonacci series up to 50\n",
    "result = fibonacci(50)\n",
    "print(result)\n",
    "\n",
    "Write a JavaScript to read HTML contents from a Web URL. Follow\n",
    "the format and labels provide below:\n",
    "Problem: \n",
    "Language:\n",
    "Code:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952b1058-6b6f-4ee2-b5b7-94cb8ee70a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: Read HTML contents from a web URL\n",
      "Language: JavaScript\n",
      "Code:\n",
      "```javascript\n",
      "const https = require('https');\n",
      "\n",
      "// Function to read HTML content from a given URL\n",
      "function readHTMLContent(url) {\n",
      "    return new Promise((resolve, reject) => {\n",
      "        https.get(url, (response) => {\n",
      "            if (response.statusCode < 200 || response.statusCode >= 300) {\n",
      "                return reject(new Error(`Request failed with status code ${response.statusCode}`));\n",
      "            }\n",
      "\n",
      "            let data = '';\n",
      "\n",
      "            // A chunk of data has been received.\n",
      "            response.on('data', (chunk) => {\n",
      "                data += chunk;\n",
      "            });\n",
      "\n",
      "            // The whole response has been received. Print out the result.\n",
      "            response.on('end', () => {\n",
      "                resolve(data);\n",
      "            });\n",
      "\n",
      "        }).on('error', (e) => {\n",
      "            reject(e);\n",
      "        });\n",
      "    });\n",
      "};\n",
      "\n",
      "// Example usage:\n",
      "const url = 'https://example.com'; // Replace with your desired URL\n",
      "\n",
      "readHTMLContent(url)\n",
      "    .then((htmlContent) => {\n",
      "        console.log(htmlContent); // Outputs the HTML content of the page\n",
      "    })\n",
      "    .catch((error) => {\n",
      "        console.error(error);\n",
      "    });\n",
      "```\n",
      "\n",
      "Before running this JavaScript code, make sure that you are operating in an environment where the `https` module is available, such as Node.js. This code will not work in a front-end JavaScript environment like a browser without additional configurations such as CORS policies or using a server-side proxy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, few_shot_code_gen_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911078d-df59-48f3-9567-4d29ddfe261d",
   "metadata": {},
   "source": [
    "### Example 3: Language transation form and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b9b24f6-c469-44bb-a955-e01bd5678dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are supreme polyglot and speak numerous languages across the globe.\"\"\"\n",
    "\n",
    "few_shot_lang_trans_prompt = \"\"\"English to {target_language} translation. \n",
    "English: What is your first and last name?\n",
    "French: Comment vous appelez-vous (pr√©nom et nom) ?\n",
    "\n",
    "English: How long have been living in Brazil?\n",
    "Protugese: H√° quanto tempo voc√™ vive no Brasil?\n",
    "\n",
    "English: What's your favorite footaball team in La Liga in Spain?\n",
    "Spanish: ¬øCu√°l es tu equipo favorito de f√∫tbol en La Liga en Espa√±a?\n",
    "\n",
    "English: When is the best time to attend October Fest in Germany, and where should I stay?\"\n",
    "Germany: Wann ist die beste Zeit, um das Oktoberfest in Deutschland zu besuchen, und wo sollte ich √ºbernachten?\n",
    "\n",
    "English: \n",
    "Mandarin:\n",
    "\n",
    "Translate the English sentences into the Germany, Spanish, and Mandarin.\n",
    "English: Who is regarded as the best footballer in England?\"\n",
    "Germany:\n",
    "Spanish:\n",
    "Mandarin:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ec9db3-e94e-44b4-b944-ab30f7149f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany: Wer gilt als der beste Fu√üballspieler in England?\n",
      "Spanish: ¬øQui√©n es considerado el mejor futbolista en Inglaterra?\n",
      "Mandarin: Ë∞ÅË¢´ËÆ§‰∏∫ÊòØËã±Ê†ºÂÖ∞ÊúÄÂ•ΩÁöÑË∂≥ÁêÉËøêÂä®ÂëòÔºü(Sh√©i b√®i r√®nw√©i sh√¨ Yƒ´ngg√©l√°n zu√¨ h«éo de z√∫qi√∫ y√πnd√≤ngyu√°n?)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, few_shot_lang_trans_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e332aa6b-2295-4421-8669-a885f812caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_prompt = \"\"\"\"Translate the English sentences into the Germany.\n",
    "English: When is the best time to attend October Fest in Germany, and where should I stay?\n",
    "Germany:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8323f240-24c0-467b-a34d-7e1dc6483ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: Wann ist die beste Zeit, um das Oktoberfest in Deutschland zu besuchen, und wo sollte ich √ºbernachten?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, lang_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0139af-fb84-4cb2-9e47-62265de8360a",
   "metadata": {},
   "source": [
    "## All this is amazing! üòú Feel the wizardy prompt power üßô‚Äç‚ôÄÔ∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
